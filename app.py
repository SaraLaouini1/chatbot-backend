
from flask import Flask, request, jsonify
from anonymization import anonymize_text
from llm_client import send_to_llm
from flask import Flask, request, jsonify
import json

from flask_cors import CORS
from dotenv import load_dotenv
import os
import re

import time
from collections import defaultdict
from datetime import datetime


load_dotenv()

app = Flask(__name__)




# Update CORS configuration at the top of app.py
CORS(app, resources={
    r"/*": {  
        "origins": [
            "https://chatbot-login.onrender.com",
            "http://localhost:5173"
        ],
        "methods": ["GET", "POST", "OPTIONS"],
        "allow_headers": ["Content-Type", "Authorization"],
        "supports_credentials": True
    }
})


@app.before_request
def log_request_info():
    app.logger.debug('Headers: %s', request.headers)
    app.logger.debug('Body: %s', request.get_data())

@app.route('/')
def health_check():
    return jsonify({"status": "active"}), 200

@app.route('/process', methods=['GET'])
def handle_get():
    return jsonify({"error": "Use POST method"}), 405

@app.route('/process', methods=['POST'])
def process_request():
    try:
        # Authentication
        auth_header = request.headers.get('Authorization')
        if not auth_header or not auth_header.startswith('Bearer '):
            return jsonify({"error": "Missing token"}), 401
            
        try:
            token = json.loads(auth_header[7:])
            if time.time() > token.get('expires', 0):
                return jsonify({"error": "Token expired"}), 401
            username = token['username']
        except:
            return jsonify({"error": "Invalid token"}), 401

        # Get existing history
        user_history = conversation_histories.get(username, [])
        
        data = request.json
        original_prompt = data.get("prompt", "")

        # ğŸ”¹ Step 1: Anonymization
        anonymized_prompt, mapping = anonymize_text(original_prompt)

        # Validate placeholders in the anonymized prompt
        #expected_placeholders = {item["anonymized"] for item in mapping}
        #found_placeholders = set(re.findall(r"<\w+_\d+>", anonymized_prompt))
        
        #if expected_placeholders != found_placeholders:
            #raise ValueError(f"Placeholder mismatch. Expected: {expected_placeholders}, Found: {found_placeholders}")

        # âœ… Better debug prints for the anonymized prompt and mapping
        print("\nğŸ“Œ **Anonymized Prompt:**\n", anonymized_prompt)
        print("\nğŸ“Œ **Mapping:**\n", json.dumps(mapping, indent=2))

        # ğŸ”¹ Step 2: Send to LLM
        mapped_placeholders = [item["anonymized"] for item in mapping]
        llm_raw_response  = send_to_llm(
            anonymized_prompt,
            placeholders=mapped_placeholders
        )

        # âœ… Debug print before recontextualization
        print("\nğŸ“Œ **LLM Response Before Cleaning:**\n", llm_raw_response )

        # ğŸ”¹ Step 3: Recontextualization - Replace anonymized placeholders with original values
        llm_after_recontext = llm_raw_response
        for item in mapping:
            placeholder = re.escape(item["anonymized"])
            llm_after_recontext = re.sub(rf'{placeholder}', item["original"], llm_after_recontext)

        # âœ… Final cleanup of unnecessary placeholders
        llm_final_response  = re.sub(r'<\w+_\d+>', '', llm_after_recontext)

        # âœ… Final debug print of cleaned response
        print("\nğŸ“Œ **Final Response (After Cleaning):**\n", llm_final_response)



        # ğŸ”¹ Step 4: Return response
        return jsonify({
            "response": llm_final_response,
            "llm_raw": llm_raw_response,
            "llm_after_recontext": llm_after_recontext,
            "anonymized_prompt": anonymized_prompt,
            "mapping": mapping
        })

    except Exception as e:
        print("âŒ Error:", str(e))
        return jsonify({"error": str(e)}), 500


if __name__ == '__main__':
    app.run(host='0.0.0.0', port=int(os.getenv('PORT', 5000)))
